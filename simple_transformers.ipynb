{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import seaborn as sns\n",
    "#from tqdm import tqdm_notebook as tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "#from tqdm import tqdm as tqdmflat\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "import torch\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "from simpletransformers.classification import ClassificationModel\n",
    "\n",
    "import logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'data/'\n",
    "biz=pd.read_csv(os.path.join(PATH,\"yelp_business.csv\"))\n",
    "reviews=pd.read_csv(os.path.join(PATH,\"yelp_review.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "col = ['neighborhood', 'address', 'latitude', 'longitude', 'stars']\n",
    "biz.drop(columns=col, inplace=True)    \n",
    "\n",
    "biz.categories = biz.categories.apply(lambda x: x.split(\";\"))\n",
    "\n",
    "biz = biz[\n",
    "    (biz.city == 'Cleveland') & \n",
    "    (biz.state == 'OH') & \n",
    "    (biz.is_open == 1) & \n",
    "    (biz.categories.apply(\n",
    "        lambda x: True if 'Restaurants' in x else False\n",
    "    ))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(reviews, biz, how='inner', on='business_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = df['stars'].apply(lambda x: 1 if x >= 4 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>name</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "      <th>categories</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OPZsR2jCG72uoDNjU71DQQ</td>\n",
       "      <td>qYbWTWH5leltA0bzWAOnmA</td>\n",
       "      <td>meXjqyhTNLFmknY39y2sMg</td>\n",
       "      <td>5</td>\n",
       "      <td>2014-09-11</td>\n",
       "      <td>Solid beers -- Christmas Ale defines my holida...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Great Lakes Brewing Company\"</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>OH</td>\n",
       "      <td>44113</td>\n",
       "      <td>751</td>\n",
       "      <td>1</td>\n",
       "      <td>[Breweries, Restaurants, Event Planning &amp; Serv...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fxGwEiSYDtAen8BNuVGGxg</td>\n",
       "      <td>8Az_JgEpXqAii_5EDkw2tw</td>\n",
       "      <td>meXjqyhTNLFmknY39y2sMg</td>\n",
       "      <td>3</td>\n",
       "      <td>2013-10-13</td>\n",
       "      <td>Meh.  It was OK.  A bartender the night before...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Great Lakes Brewing Company\"</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>OH</td>\n",
       "      <td>44113</td>\n",
       "      <td>751</td>\n",
       "      <td>1</td>\n",
       "      <td>[Breweries, Restaurants, Event Planning &amp; Serv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gweb4pADeQ26WnaiKEZ7GQ</td>\n",
       "      <td>T9tEic49JZjN4nCUcDvrRQ</td>\n",
       "      <td>meXjqyhTNLFmknY39y2sMg</td>\n",
       "      <td>4</td>\n",
       "      <td>2014-01-15</td>\n",
       "      <td>Oh Christmas Ale, oh Christmas Ale, how lovely...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Great Lakes Brewing Company\"</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>OH</td>\n",
       "      <td>44113</td>\n",
       "      <td>751</td>\n",
       "      <td>1</td>\n",
       "      <td>[Breweries, Restaurants, Event Planning &amp; Serv...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P1vhwPI56SeZEz10ywaS7w</td>\n",
       "      <td>W1p8_CFW5FISSihmQo5Qzw</td>\n",
       "      <td>meXjqyhTNLFmknY39y2sMg</td>\n",
       "      <td>3</td>\n",
       "      <td>2012-02-09</td>\n",
       "      <td>What is the big deal about this place? The foo...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Great Lakes Brewing Company\"</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>OH</td>\n",
       "      <td>44113</td>\n",
       "      <td>751</td>\n",
       "      <td>1</td>\n",
       "      <td>[Breweries, Restaurants, Event Planning &amp; Serv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1kQvQlBX0V5_rGddBh9-rQ</td>\n",
       "      <td>Y_PP05RRdzbKRYfDCCfh8w</td>\n",
       "      <td>meXjqyhTNLFmknY39y2sMg</td>\n",
       "      <td>5</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>Great Lakes Brewing Company is one of my favor...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Great Lakes Brewing Company\"</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>OH</td>\n",
       "      <td>44113</td>\n",
       "      <td>751</td>\n",
       "      <td>1</td>\n",
       "      <td>[Breweries, Restaurants, Event Planning &amp; Serv...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  OPZsR2jCG72uoDNjU71DQQ  qYbWTWH5leltA0bzWAOnmA  meXjqyhTNLFmknY39y2sMg   \n",
       "1  fxGwEiSYDtAen8BNuVGGxg  8Az_JgEpXqAii_5EDkw2tw  meXjqyhTNLFmknY39y2sMg   \n",
       "2  Gweb4pADeQ26WnaiKEZ7GQ  T9tEic49JZjN4nCUcDvrRQ  meXjqyhTNLFmknY39y2sMg   \n",
       "3  P1vhwPI56SeZEz10ywaS7w  W1p8_CFW5FISSihmQo5Qzw  meXjqyhTNLFmknY39y2sMg   \n",
       "4  1kQvQlBX0V5_rGddBh9-rQ  Y_PP05RRdzbKRYfDCCfh8w  meXjqyhTNLFmknY39y2sMg   \n",
       "\n",
       "   stars        date                                               text  \\\n",
       "0      5  2014-09-11  Solid beers -- Christmas Ale defines my holida...   \n",
       "1      3  2013-10-13  Meh.  It was OK.  A bartender the night before...   \n",
       "2      4  2014-01-15  Oh Christmas Ale, oh Christmas Ale, how lovely...   \n",
       "3      3  2012-02-09  What is the big deal about this place? The foo...   \n",
       "4      5  2017-04-30  Great Lakes Brewing Company is one of my favor...   \n",
       "\n",
       "   useful  funny  cool                           name       city state  \\\n",
       "0       1      1     1  \"Great Lakes Brewing Company\"  Cleveland    OH   \n",
       "1       0      1     0  \"Great Lakes Brewing Company\"  Cleveland    OH   \n",
       "2       1      1     1  \"Great Lakes Brewing Company\"  Cleveland    OH   \n",
       "3       2      1     1  \"Great Lakes Brewing Company\"  Cleveland    OH   \n",
       "4       0      0     0  \"Great Lakes Brewing Company\"  Cleveland    OH   \n",
       "\n",
       "  postal_code  review_count  is_open  \\\n",
       "0       44113           751        1   \n",
       "1       44113           751        1   \n",
       "2       44113           751        1   \n",
       "3       44113           751        1   \n",
       "4       44113           751        1   \n",
       "\n",
       "                                          categories  target  \n",
       "0  [Breweries, Restaurants, Event Planning & Serv...       1  \n",
       "1  [Breweries, Restaurants, Event Planning & Serv...       0  \n",
       "2  [Breweries, Restaurants, Event Planning & Serv...       1  \n",
       "3  [Breweries, Restaurants, Event Planning & Serv...       0  \n",
       "4  [Breweries, Restaurants, Event Planning & Serv...       1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare X & Y\n",
    "Y = df['target']\n",
    "X = df['text']\n",
    "\n",
    "# Let's stratify the data so we get a fair balance\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.25, random_state=42, stratify=Y, shuffle=True\n",
    ")\n",
    "\n",
    "X_trn, X_val, y_trn, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.1, random_state=2718, stratify=y_train, shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up parameters\n",
    "params = {\n",
    "    \"fp16\":False, \n",
    "    \"use_early_stopping\": True,\n",
    "    \"early_stopping_delta\": 0.01,\n",
    "    \"early_stopping_metric\": \"mcc\",\n",
    "    \"early_stopping_metric_minimize\": False,\n",
    "    \"early_stopping_patience\": 5,\n",
    "    #\"evaluate_during_training_steps\": 1000, \n",
    "    #\"max_seq_length\": 30,\n",
    "    \"learning rate\": 3e-5,\n",
    "    #\"train_batch_size\": 8,\n",
    "    #\"eval_batch_size\": 8, \n",
    "    #\"silent\": True,\n",
    "    \"overwrite_output_dir\": True,\n",
    "    \"num_train_epochs\": 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up variables for kfold loop\n",
    "n_splits = 10\n",
    "kfold = StratifiedKFold(\n",
    "    n_splits=n_splits, \n",
    "    shuffle=True, \n",
    "    random_state=42\n",
    "    )\n",
    "\n",
    "BERT_predict = np.zeros(X_train.shape[0])\n",
    "BERT_proba = np.zeros(X_train.shape[0])\n",
    "cv_score = []\n",
    "fold = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# This step is memory intensive\n",
    "gc.collect()\n",
    "\n",
    "BERT_predict = np.zeros(X_train.shape[0])\n",
    "BERT_proba = np.zeros(X_train.shape[0])\n",
    "cv_score = []\n",
    "fold = 0\n",
    "fold = 0\n",
    "# Begin kfold loop\n",
    "for train_index, val_index in tqdm(kfold.split(X_train, y_train), total=n_splits):\n",
    "  # Set up model\n",
    "  BERT_model = ClassificationModel(\n",
    "      #\"distilbert\", \"distilbert-base-uncased\", \n",
    "      \"electra\", \"google/electra-small-discriminator\",\n",
    "      num_labels=2, args=params\n",
    "      )\n",
    "\n",
    "  # Create training set\n",
    "  train_df = pd.merge(\n",
    "      X_train.iloc[train_index], \n",
    "      y_train.iloc[train_index], \n",
    "      left_index=True, \n",
    "      right_index=True\n",
    "      )\n",
    "\n",
    "    \n",
    "  # Create validation set\n",
    "  val_df = pd.merge(\n",
    "      X_train.iloc[val_index], \n",
    "      y_train.iloc[val_index], \n",
    "      left_index=True, \n",
    "      right_index=True\n",
    "      )\n",
    "  \n",
    "  # Fit model\n",
    "  BERT_model.train_model(train_df)\n",
    " \n",
    "  # Calculate score\n",
    "  result, model_outputs, wrong_predictions = BERT_model.eval_model(\n",
    "      val_df, \n",
    "      acc=accuracy_score\n",
    "      )\n",
    "  \n",
    "  # Calculate Probability\n",
    "  pred, proba = BERT_model.predict(list(X_train))\n",
    "  \n",
    "  # Clear data to save memory\n",
    "  del BERT_model\n",
    "  gc.collect()\n",
    "\n",
    "  # Add to Lists\n",
    "  cv_score.append(result['acc'])\n",
    "  BERT_predict += pred\n",
    "  BERT_proba += proba[:,1]\n",
    "\n",
    "  # Present Counter\n",
    "  fold += 1\n",
    "  print(f'\\nFold {fold} out of {n_splits} complete!\\n')\n",
    "  \n",
    "print('Evaluation Complete\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "del BERT_model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up parameters\n",
    "params = {\n",
    "    \"fp16\":False, \n",
    "    \"use_early_stopping\": True,\n",
    "    \"early_stopping_delta\": 0.01,\n",
    "    \"early_stopping_metric\": \"mcc\",\n",
    "    \"early_stopping_metric_minimize\": False,\n",
    "    \"early_stopping_patience\": 5,\n",
    "    #\"evaluate_during_training_steps\": 1000, \n",
    "    #\"max_seq_length\": 30,\n",
    "    \"learning rate\": 3e-5,\n",
    "    \"train_batch_size\": 50,\n",
    "    \"eval_batch_size\": 50, \n",
    "    #\"silent\": True,\n",
    "    \"overwrite_output_dir\": True,\n",
    "    \"num_train_epochs\": 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7e42287d3264fe396caef6e2ecf13fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=38413.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2fe01e36cd243dcb7cdf157ee4b26a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=5.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fc3a46c929b4cbeb5f42587096ea986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Current iteration', max=4802.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Running loss: 0.694625\r",
      "Running loss: 0.685928"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/conda-bld/pytorch_1587428398394/work/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 0.645090"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/koryd/miniconda3/envs/yelp/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:231: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 0.840242\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-b8cb7a7bb13a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m# Fit model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mBERT_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;31m# Calculate score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/yelp/lib/python3.7/site-packages/simpletransformers/classification/classification_model.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, train_df, multi_label, output_dir, show_running_loss, args, eval_df, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0meval_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m         )\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/yelp/lib/python3.7/site-packages/simpletransformers/classification/classification_model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_dataset, output_dir, multi_label, show_running_loss, eval_df, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# mean() to average on multi-gpu parallel training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m                 \u001b[0mcurrent_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshow_running_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "\n",
    "BERT_predict = np.zeros(X_train.shape[0])\n",
    "BERT_proba = np.zeros(X_train.shape[0])\n",
    "cv_score = []\n",
    "fold = 0\n",
    "fold = 0\n",
    "\n",
    "BERT_model = ClassificationModel(\n",
    "  \"distilbert\", \"distilbert-base-uncased\", \n",
    "  #\"electra\", \"google/electra-small-discriminator\",\n",
    "  num_labels=2, args=params\n",
    "  )\n",
    "\n",
    "# Create training set\n",
    "train_df = pd.merge(\n",
    "  X_trn, \n",
    "  y_trn, \n",
    "  left_index=True, \n",
    "  right_index=True\n",
    "  )\n",
    "\n",
    "\n",
    "# Create validation set\n",
    "val_df = pd.merge(\n",
    "  X_val, \n",
    "  y_val, \n",
    "  left_index=True, \n",
    "  right_index=True\n",
    "  )\n",
    "\n",
    "test_df = pd.merge(\n",
    "    X_test,\n",
    "    y_test,\n",
    "    left_index=True,\n",
    "    right_index=True\n",
    ")\n",
    "\n",
    "train_df.columns = ['text', 'labels']\n",
    "val_df.columns = ['text', 'labels']\n",
    "test_df.columns = ['text', 'labels']\n",
    "\n",
    "# Fit model\n",
    "BERT_model.train_model(train_df, eval_df=val_df)\n",
    "\n",
    "# Calculate score\n",
    "result, model_outputs, wrong_predictions = BERT_model.eval_model(\n",
    "  test_df, \n",
    "  acc=accuracy_score\n",
    "  )\n",
    "\n",
    "# Calculate Probability\n",
    "pred, proba = BERT_model.predict(list(X_test))\n",
    "\n",
    "# Clear data to save memory\n",
    "#del BERT_model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Add to Lists\n",
    "cv_score.append(result['acc'])\n",
    "BERT_predict = pred\n",
    "BERT_proba = proba[:,1]\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf4905b756e3415aaf853bf50dfb7078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14228.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "529f1aa00ba34467aac8ec8f2cb9a460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1779.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pred, proba = BERT_model.predict(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.86      0.83      4423\n",
      "           1       0.93      0.91      0.92      9805\n",
      "\n",
      "    accuracy                           0.89     14228\n",
      "   macro avg       0.87      0.88      0.88     14228\n",
      "weighted avg       0.89      0.89      0.89     14228\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(pred, y_test))\n",
    "BERT_predict = pred\n",
    "BERT_proba = proba[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39633"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "del BERT_model\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"fp16\":False, \n",
    "    \"use_early_stopping\": True,\n",
    "    \"early_stopping_delta\": 0.05,\n",
    "    #\"early_stopping_metric\": \"mcc\",\n",
    "    #\"early_stopping_metric_minimize\": False,\n",
    "    \"early_stopping_patience\": 50,\n",
    "    #\"max_seq_length\": 30,\n",
    "    \"learning rate\": 1e-3,\n",
    "    \"train_batch_size\": 50,\n",
    "    \"eval_batch_size\": 50, \n",
    "    \"evaluate_during_training\": True,\n",
    "    \"evaluate_during_training_steps\": 100,\n",
    "    \"evaluate_during_training_verbose\": True,\n",
    "    #\"silent\": True,\n",
    "    \"overwrite_output_dir\": True,\n",
    "    \"num_train_epochs\": 3,\n",
    "    \"do_lower_case\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0754f9e04fb4214b98d4568280c949d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=38413.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6336753d8f55498dba883ca8d9fc3532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=3.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65d61a14079b4d748de929e5f0cc6cbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Current iteration', max=769.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Running loss: 0.688588"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/conda-bld/pytorch_1587428398394/work/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 0.397807"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/koryd/miniconda3/envs/yelp/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:231: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 0.384651"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/koryd/miniconda3/envs/yelp/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:200: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n",
      "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 0.210187\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea8edf19f165461e811a9c1904190e5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Current iteration', max=769.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 0.520770\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6a02454599e4d11a522a8efea1527a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Current iteration', max=769.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 0.003641\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beea46795d9f4bccb0e6c41ca4e6a07a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14228.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "907b4861f9894e48827e296fc28f295b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=285.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5c6acb7d136440ba87a3ec4aeda04f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14228.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3be6ee0a416a4896bbf8cc729e29fe64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=285.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gc.collect()\n",
    "\n",
    "BERT_predict = np.zeros(X_train.shape[0])\n",
    "BERT_proba = np.zeros(X_train.shape[0])\n",
    "cv_score = []\n",
    "fold = 0\n",
    "fold = 0\n",
    "\n",
    "BERT_model = ClassificationModel(\n",
    "  \"distilbert\", \"distilbert-base-uncased\", \n",
    "  #\"electra\", \"google/electra-small-discriminator\",\n",
    "  num_labels=2, args=params\n",
    "  )\n",
    "\n",
    "# Create training set\n",
    "train_df = pd.merge(\n",
    "  X_trn, \n",
    "  y_trn, \n",
    "  left_index=True, \n",
    "  right_index=True\n",
    "  )\n",
    "\n",
    "\n",
    "# Create validation set\n",
    "val_df = pd.merge(\n",
    "  X_val, \n",
    "  y_val, \n",
    "  left_index=True, \n",
    "  right_index=True\n",
    "  )\n",
    "\n",
    "test_df = pd.merge(\n",
    "    X_test,\n",
    "    y_test,\n",
    "    left_index=True,\n",
    "    right_index=True\n",
    ")\n",
    "\n",
    "train_df.columns = ['text', 'labels']\n",
    "val_df.columns = ['text', 'labels']\n",
    "test_df.columns = ['text', 'labels']\n",
    "\n",
    "# Fit model\n",
    "BERT_model.train_model(train_df, eval_df=val_df)\n",
    "\n",
    "# Calculate score\n",
    "result, model_outputs, wrong_predictions = BERT_model.eval_model(\n",
    "  test_df, \n",
    "  acc=accuracy_score\n",
    "  )\n",
    "\n",
    "# Calculate Probability\n",
    "pred, proba = BERT_model.predict(list(X_test))\n",
    "\n",
    "# Clear data to save memory\n",
    "#del BERT_model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Add to Lists\n",
    "cv_score.append(result['acc'])\n",
    "BERT_predict = pred\n",
    "BERT_proba = proba[:,1]\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.85      4635\n",
      "           1       0.93      0.92      0.93      9593\n",
      "\n",
      "    accuracy                           0.90     14228\n",
      "   macro avg       0.89      0.89      0.89     14228\n",
      "weighted avg       0.90      0.90      0.90     14228\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(pred, y_test))\n",
    "BERT_predict = pred\n",
    "BERT_proba = proba[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91df8eafe2964dbda674c4aa84e0de49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14228.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01d83ff9d8294a3b9d4632f94fb786e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=285.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.85      4411\n",
      "           1       0.94      0.92      0.93      9817\n",
      "\n",
      "    accuracy                           0.91     14228\n",
      "   macro avg       0.89      0.90      0.89     14228\n",
      "weighted avg       0.91      0.91      0.91     14228\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = ClassificationModel('distilbert', 'outputs/best_model', args={})\n",
    "pred, proba = model.predict(X_test.values)\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare X & Y\n",
    "Ys = df['stars'] - 1\n",
    "Xs = df['text']\n",
    "\n",
    "# Let's stratify the data so we get a fair balance\n",
    "Xs_train, Xs_test, ys_train, ys_test = train_test_split(\n",
    "    Xs, Ys, test_size=0.25, random_state=42, stratify=Y, shuffle=True\n",
    ")\n",
    "\n",
    "Xs_trn, Xs_val, ys_trn, ys_val = train_test_split(\n",
    "    Xs_train, ys_train, test_size=0.1, random_state=2718, stratify=y_train, shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"fp16\":False, \n",
    "    \"use_early_stopping\": True,\n",
    "    \"early_stopping_delta\": 0.05,\n",
    "    #\"early_stopping_metric\": \"mcc\",\n",
    "    #\"early_stopping_metric_minimize\": False,\n",
    "    \"early_stopping_patience\": 50,\n",
    "    #\"max_seq_length\": 30,\n",
    "    \"learning rate\": 1e-3,\n",
    "    \"train_batch_size\": 50,\n",
    "    \"eval_batch_size\": 50, \n",
    "    \"evaluate_during_training\": True,\n",
    "    \"evaluate_during_training_steps\": 100,\n",
    "    \"evaluate_during_training_verbose\": True,\n",
    "    #\"silent\": True,\n",
    "    \"overwrite_output_dir\": True,\n",
    "    \"num_train_epochs\": 3,\n",
    "    \"do_lower_case\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0182aae47b2f49a3a5c74d995b7f8f1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=38413.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5f07f06117040ce86c33554d6452d3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=3.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eea649f91ed4417c8ee82bb4f74f4355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Current iteration', max=769.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 1.579074\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/yelp/lib/python3.7/site-packages/simpletransformers/classification/classification_model.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, train_df, multi_label, output_dir, show_running_loss, args, eval_df, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0meval_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m         )\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/yelp/lib/python3.7/site-packages/simpletransformers/classification/classification_model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_dataset, output_dir, multi_label, show_running_loss, eval_df, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# mean() to average on multi-gpu parallel training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m                 \u001b[0mcurrent_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshow_running_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gc.collect()\n",
    "\n",
    "BERT_predict = np.zeros(Xs_train.shape[0])\n",
    "BERT_proba = np.zeros(Xs_train.shape[0])\n",
    "cv_score = []\n",
    "fold = 0\n",
    "fold = 0\n",
    "\n",
    "BERT_model = ClassificationModel(\n",
    "  \"distilbert\", \"distilbert-base-uncased\", \n",
    "  #\"electra\", \"google/electra-small-discriminator\",\n",
    "  num_labels=5, args=params\n",
    "  )\n",
    "\n",
    "# Create training set\n",
    "train_df = pd.merge(\n",
    "  Xs_trn, \n",
    "  ys_trn, \n",
    "  left_index=True, \n",
    "  right_index=True\n",
    "  )\n",
    "\n",
    "\n",
    "# Create validation set\n",
    "val_df = pd.merge(\n",
    "  Xs_val, \n",
    "  ys_val, \n",
    "  left_index=True, \n",
    "  right_index=True\n",
    "  )\n",
    "\n",
    "test_df = pd.merge(\n",
    "    Xs_test,\n",
    "    ys_test,\n",
    "    left_index=True,\n",
    "    right_index=True\n",
    ")\n",
    "\n",
    "train_df.columns = ['text', 'labels']\n",
    "val_df.columns = ['text', 'labels']\n",
    "test_df.columns = ['text', 'labels']\n",
    "\n",
    "# Fit model\n",
    "BERT_model.train_model(train_df, eval_df=val_df)\n",
    "\n",
    "# Calculate score\n",
    "result, model_outputs, wrong_predictions = BERT_model.eval_model(\n",
    "  test_df, \n",
    "  acc=accuracy_score\n",
    "  )\n",
    "\n",
    "# Calculate Probability\n",
    "pred, proba = BERT_model.predict(list(Xs_test))\n",
    "\n",
    "# Clear data to save memory\n",
    "#del BERT_model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Add to Lists\n",
    "cv_score.append(result['acc'])\n",
    "BERT_predict = pred\n",
    "BERT_proba = proba[:,1]\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_metrics(model_sum):\n",
    "    # Print cross-validation scores\n",
    "    print(\"Cross Validation Scores\\n\" + 23*\"=\" + \"\\n{}\\n\".format(model_sum['cv_scores']))\n",
    "    print(\"Average CV = {}\\n\".format(model_sum['cv_mean']))\n",
    "    \n",
    "    # Print classification report\n",
    "    print(\"Classification Report\\n\" + 21*\"=\" + \"\\n\" + model_sum['class_report'])\n",
    "    \n",
    "    # Print confusion matrix results\n",
    "    print(\"Confusion Matrix\\n\" + 16*\"=\" + '\\nTrue Positives = {}\\nTrue Negatives'\\\n",
    "          '= {}\\nFalse Positives = {}\\nFalse Negatives = {}'\\\n",
    "          .format(model_sum['true positives'], \n",
    "                  model_sum['true negatives'], \n",
    "                  model_sum['false positives'], \n",
    "                  model_sum['false negatives']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ELECTRA Classification Model\n",
      "Cross Validation Scores\n",
      "=======================\n",
      "[0.8909193140286759]\n",
      "\n",
      "Average CV = 0.8909193140286759\n",
      "\n",
      "Classification Report\n",
      "=====================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83      4672\n",
      "           1       0.91      0.93      0.92      9556\n",
      "\n",
      "    accuracy                           0.89     14228\n",
      "   macro avg       0.88      0.87      0.88     14228\n",
      "weighted avg       0.89      0.89      0.89     14228\n",
      "\n",
      "Confusion Matrix\n",
      "================\n",
      "True Positives = 8842\n",
      "True Negatives= 3834\n",
      "False Positives = 838\n",
      "False Negatives = 714\n"
     ]
    }
   ],
   "source": [
    "# Get average prediction of each model\n",
    "#BERT_predict /= n_splits\n",
    "#BERT_proba /= n_splits\n",
    "    \n",
    "# Create confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test.values, pred).ravel()\n",
    "    \n",
    "# Save metrics in a dictionary\n",
    "BERT_results = {}\n",
    "    \n",
    "BERT_results['cv_scores'] = cv_score\n",
    "BERT_results['cv_mean'] = np.mean(cv_score)\n",
    "    \n",
    "BERT_results['true negatives'] = tn\n",
    "BERT_results['false positives'] = fp\n",
    "BERT_results['false negatives'] = fn\n",
    "BERT_results['true positives'] = tp\n",
    "BERT_results['accuracy'] = (tp+tn)/len(BERT_predict)\n",
    "BERT_results['f1 score'] = 2*tp/(2*tp+fp+fn)\n",
    "BERT_results['class_report'] = classification_report(y_test, BERT_predict.round())\n",
    "\n",
    "# Print results\n",
    "print('\\nELECTRA Classification Model')\n",
    "format_metrics(BERT_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('yelp': conda)",
   "language": "python",
   "name": "python37764bityelpcondaa94490cf09d448ff98cce07bb2e1986f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
